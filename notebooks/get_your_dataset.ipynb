{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W2LDC-PbXhtR"
   },
   "source": [
    "В этой тетрадке мы поговорим о способах собрать свой датасет для исследований: откуда брать данные, как их собирать и как хранить."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Существует несколько библиотек(модулей) для работы с веб-страничками, сегодня мы будем использовать requests для доступа к веб-страничкам и Beautiful Soup для работы с содержимым html-документов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-19T07:43:42.215240Z",
     "start_time": "2020-12-19T07:43:42.162193Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "ncJ-uAqjDNkC",
    "outputId": "b58e536a-5828-42b5-8cbd-ba766ee76384",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip3 install requests #ставим модуль requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-19T07:11:35.137512Z",
     "start_time": "2020-12-19T07:11:33.589516Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "fFcBQ25GZBCO",
    "outputId": "4d52810c-2a47-486a-f79b-1ed4621c8793",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ставим модуль beautifulsoup, самая последняя версия - четвертая\n",
    "! pip3 install beautifulsoup4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-19T08:18:38.198003Z",
     "start_time": "2020-12-19T08:18:38.186002Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "XT5G41FYnr7a"
   },
   "outputs": [],
   "source": [
    "# импортируем модули в тетрадку\n",
    "\n",
    "import requests as rq\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cIvQNBqUYwE8"
   },
   "source": [
    "# Как работать с веб-страничками"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "28Oy0NnLnk0L"
   },
   "source": [
    "### Шаг 1. \n",
    "\n",
    "Создадим переменную ```url``` и сохраним в нее адрес какой-нибудь html-страницы\n",
    "\n",
    "например, [сайта CNN](http://lite.cnn.io/en)\n",
    "\n",
    "обратите внимание, что адрес прописываем в кавычках, как строку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-19T08:22:23.420826Z",
     "start_time": "2020-12-19T08:22:23.416822Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "WzqN6Ss_aujY"
   },
   "outputs": [],
   "source": [
    "url = 'https://edition.cnn.com/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ysgl6VmpKjxu"
   },
   "source": [
    "В модуле requests есть метод request.get(), который сохраняет ответ сервера на наш реквест. Мы применим его к переменной url, куда сохранен путь к странице. \n",
    "Сохраним результат в переменную page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-19T08:46:54.806718Z",
     "start_time": "2020-12-19T08:46:54.506720Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "O8AH4kDxqKvF"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = rq.get(url) \n",
    "\n",
    "page # посмотрим на код ответа, если 200, все хорошо"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J5Y2C39Gp0yK"
   },
   "source": [
    "код 200 сообщает, что страница загружена успешно \n",
    "*(коды, начинающиеся с 2, обычно указывают на успешное выполнение операции, а коды, начинающиеся с 4 или 5, сообщают об ошибке)*\n",
    "\n",
    "Узнать больше о кодах состояния HTTP  можно [по этой ссылке.](https://www.w3.org/Protocols/HTTP/1.1/draft-ietf-http-v11-spec-01#Status-Codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Gg53fJKNObR"
   },
   "source": [
    "Следующим шагом нужно получить доступ к текстовому содержимому веб-файлов.\n",
    "\n",
    "Здесь нам поможет page.text *(или page.content, чтобы получить значение в байтах)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-19T08:47:01.231718Z",
     "start_time": "2020-12-19T08:47:01.108719Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "md61SNPYu_jL",
    "tags": []
   },
   "outputs": [],
   "source": [
    "page.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X5cEfTSEYhcY"
   },
   "source": [
    "### Шаг2\n",
    "\n",
    "Поработаем с текстом на страничке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vcVMhwpHNxE5"
   },
   "source": [
    "Мы получили текст страницы (со всеми html-тегами), однако его неудобно прочитать в таком виде. \n",
    "\n",
    "Здесь нам понадобится Beautiful Soup, модуль для html-парсинга: он сделает текст веб-страницы, извлеченный с помощью Requests, более читаемым, потому что создает дерево синтаксического разбора из проанализированных HTML (или XML) документов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-19T09:20:00.809844Z",
     "start_time": "2020-12-19T09:20:00.351849Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "GOBPlBro3AQR"
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.text, 'html.parser') #сохраним результат в переменную soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-19T08:47:09.815788Z",
     "start_time": "2020-12-19T08:47:09.553787Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "HigX0lNr3P1Z",
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(soup.prettify()) # показывает нашу страницу в красивом виде"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг3 \n",
    "время доставать всякие тэги "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bVR8OVuRUaO1"
   },
   "source": [
    "предыдущие шаги позволили привести веб-страничку к виду, где содержание каждого тега написано с новой строки. \n",
    "\n",
    "Некоторые теги полезны для конкретной задачи (там текст), некоторые - не очень (например, мета-данные,картинки и тд)\n",
    "\n",
    "Извлечь один тег со страницы можно с помощью метода find_all(). Он похож на метод регулярок, с которым мы работали: он вернет все экземпляры данного тега в документе. Нужно прописать в скобках метода нужный тег. \n",
    "\n",
    "### Самые популярные теги:\n",
    "    <h1-h6> - заголовки\n",
    "    <div> для целых \"блоков\" странички\n",
    "    <li> список с перечислением\n",
    "    <p> для текста\n",
    "    <a> для гиперссылок\n",
    "    <img> для изображений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<title>CNN International - Breaking News, US News, World News and Video</title>,\n",
       " <title id=\"searchIconTitle\">Search CNN</title>,\n",
       " <title id=\"menuIconTitle\">Open Menu</title>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(\"title\") # тег нужно записать без треугольных скобочек\n",
    "\n",
    "# попробуйте теги head, body, title, div и др"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А так можно достать нужные части тега (напимер, текст)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-19T08:50:08.027471Z",
     "start_time": "2020-12-19T08:50:08.007477Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "N0RXeVL33W7I",
    "outputId": "03346e7c-dc54-4183-a943-35c61ba969a6",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN International - Breaking News, US News, World News and Video\n",
      "Search CNN\n",
      "Open Menu\n"
     ]
    }
   ],
   "source": [
    "for x in soup.find_all('title'):\n",
    "    print(x.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Весь текст на страничке за раз можно достать еще и так\n",
    "soup.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Как создать корпус"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, мы определили нужные теги и напарсили необходимые данные. Пора сохранить их в файл. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# в .txt\n",
    "\n",
    "with open(\"../data/CNN.txt\", \"a\") as file:\n",
    "    for x in soup.find_all(\"title\"):\n",
    "        file.write(x.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   или в .csv\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = {} # создадим словарь, а из него датафрейм\n",
    "\n",
    "for idx, x in enumerate(soup.find_all(\"title\")):\n",
    "    data.update({idx:[x.text,url]})\n",
    "\n",
    "    \n",
    "df = pd.DataFrame.from_dict(data,columns=[\"content\",\"source\"], orient=\"index\")\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохраняем\n",
    "df.to_csv(\"../data/CNN.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tF72_zk5ak4g"
   },
   "source": [
    "# полезные ссылки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что почитать об использовании данных\n",
    "- [как устроен сбор данных](https://en.wikipedia.org/wiki/Web_scraping)\n",
    "\n",
    "\n",
    "- закон об авторском праве ([в деталях](http://www.consultant.ru/document/cons_doc_LAW_64629/0b318126c43879a845405f1fb1f4342f473a1eda/), [вкратце](https://ru.wikipedia.org/wiki/%D0%90%D0%B2%D1%82%D0%BE%D1%80%D1%81%D0%BA%D0%BE%D0%B5_%D0%BF%D1%80%D0%B0%D0%B2%D0%BE_%D0%B2_%D0%A0%D0%BE%D1%81%D1%81%D0%B8%D0%B8))\n",
    "- [закон о персональных данных](http://www.consultant.ru/document/cons_doc_LAW_61801/)\n",
    "\n",
    "\n",
    "- [типы лицензирования данных](https://docs.github.com/en/repositories/managing-your-repositorys-settings-and-features/customizing-your-repository/licensing-a-repository)\n",
    "- [FAIR data](https://en.wikipedia.org/wiki/FAIR_data)\n",
    "- [OpenData](https://en.wikipedia.org/wiki/Open_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Гайды и туториалы\n",
    "\n",
    "- [документация requests и быстрый гайд](https://requests.readthedocs.io/en/master/user/quickstart/)\n",
    "\n",
    "\n",
    "- [документация Beautiful Soup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "\n",
    "- [text-only](https://sjmulder.nl/en/textonly.html) веб-сайты, чтобы легко начать парсить\n",
    "\n",
    "\n",
    "\n",
    "- [здесь](https://www.york.ac.uk/teaching/cws/wws/webpage1.html) можно почитать про структуру html подробнее\n",
    "\n",
    "\n",
    "- [здесь](https://www.w3schools.com/html/html_examples.asp) еще и потренироваться в режиме онлайн"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ILp0Ke2daokq"
   },
   "source": [
    "Чем парсить соцсети (не исчерпывающий список)\n",
    "\n",
    "- [Twitter](https://developer.twitter.com/en/docs/twitter-api/tools-and-libraries/v2)\n",
    "- [Meta](https://developers.facebook.com/docs/graph-api/)\n",
    "- [VK](https://vk-api.readthedocs.io/en/latest/), [положения о прайваси](https://vk.com/dev/uprivacy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Практика\n",
    "\n",
    "давайте попарсим другой адрес и вытащим оттуда весь текст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://en.wikipedia.org/wiki/Welsh_Corgi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "get_your_dataset.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
